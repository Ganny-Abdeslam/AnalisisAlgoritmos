@article{doi:10.1155/2013/301875,
author = {P. Carlone and I. Baran and J. H. Hattel and G. S. Palazzo},
title = {Computational Approaches for Modeling the Multiphysics in Pultrusion Process},
journal = {Advances in Mechanical Engineering},
volume = {5},
number = { },
pages = {301875},
year = {2013a},
doi = {10.1155/2013/301875},
URL = {https://doi-org.crai.referencistas.com/10.1155/2013/301875},
eprint = {https://doi-org.crai.referencistas.com/10.1155/2013/301875},
abstract = {Pultrusion is a continuous manufacturing process used to produce high strength composite profiles with constant cross section. The mutual interactions between heat transfer, resin flow and cure reaction, variation in the material properties, and stress/distortion evolutions strongly affect the process dynamics together with the mechanical properties and the geometrical precision of the final product. In the present work, pultrusion process simulations are performed for a unidirectional (UD) graphite/epoxy composite rod including several processing physics, such as fluid flow, heat transfer, chemical reaction, and solid mechanics. The pressure increase and the resin flow at the tapered inlet of the die are calculated by means of a computational fluid dynamics (CFD) finite volume model. Several models, based on different homogenization levels and solution schemes, are proposed and compared for the evaluation of the temperature and the degree of cure distributions inside the heating die and at the postdie region. The transient stresses, distortions, and pull force are predicted using a sequentially coupled three-dimensional (3D) thermochemical analysis together with a 2D plane strain mechanical analysis using the finite element method and compared with results obtained from a semianalytical approach.}
}

@article{doi:10.1243/0954411021536351,
author = {J S Cole and L D Wijesinghe and J K Watterson and D J A Scott},
title = {Computational and experimental simulations of the haemodynamics at cuffed arterial bypass graft anastomoses},
journal = {Proceedings of the Institution of Mechanical Engineers, Part H: Journal of Engineering in Medicine},
volume = {216},
number = {2},
pages = {135–143},
year = {2002b},
doi = {10.1243/0954411021536351},
note = {PMID:12022420},
URL = {https://doi-org.crai.referencistas.com/10.1243/0954411021536351},
eprint = {https://doi-org.crai.referencistas.com/10.1243/0954411021536351},
abstract = {Abstract The development of intimal hyperplasia at arterial bypass graft anastomoses is a major factor responsible for graft failure. A revised surgical technique, involving the incorporation of a small section of vein (vein cuff) into the distal anastomosis of polytetrafluoroethylene (PTFE) grafts, alters the distribution of intimal hyperplasia and improves graft performance. Numerical and in vitro flow visualization experiments have been conducted to identify the flow behaviour in the cuffed bypass model and to determine whether the improved performance of the cuffed system can be accounted for by haemodynamic factors. The flowfield at the cuffed anastomosis is characterized by an expansive recirculation. Separation occurs at the graft heel, and at the cuff toe as the blood enters the recipient artery. Wall shear stresses in the vicinity of the cuff heel are low, but high shear stresses and large spatial gradients in the shearing force act for a time on the artery floor. In the conventional model, a less disturbed flow prevails while the gradients of shear stress on the floor are smaller. Aspects of the anastomotic haemodynamics are worsened when the cuff is employed. The superior patency rates of cuffed bypasses may not be explained purely on the basis of local haemodynamic factors.}
}

@article{doi:10.1177/0022002714540473,
author = {Stephanie Dornschneider and Nick Henderson},
title = {A Computational Model of Cognitive Maps: Analyzing Violent and Nonviolent Activity in Egypt and Germany},
journal = {Journal of Conflict Resolution},
volume = {60},
number = {2},
pages = {368–399},
year = {2016c},
doi = {10.1177/0022002714540473},
URL = {https://doi-org.crai.referencistas.com/10.1177/0022002714540473},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0022002714540473},
abstract = {Why do some individuals pick up arms as opposed to others who live under the same conditions? Environmental and group theories fail to differentiate between these individuals. In response, we apply the cognitive mapping approach and model violence as decisions based on chains of beliefs about various types of factors, including state aggression, access to violent groups, religion, and personal characteristics. Based on a double-paired comparison, data are constructed from ethnographic interviews with Muslim and non-Muslim individuals engaging in violent and nonviolent activity in authoritarian and democratic states—Egypt and Germany. The analysis develops a computational model formalizing the cognitive maps into Bayesian networks. In 477,604 runs, the model (1) identifies the beliefs connected to decisions, (2) traces inference chains antecedent to decisions, and (3) explores counterfactuals. This suggests that both violent and nonviolent activities are responses to state aggression, and not to Islam, group access, or personal characteristics.}
}

@article{doi:10.1177/0894439305282430,
author = {Lawrence A. Kuznar},
title = {High-Fidelity Computational Social Science in Anthropology: Prospects for Developing a Comparative Framework},
journal = {Social Science Computer Review},
volume = {24},
number = {1},
pages = {15–29},
year = {2006d},
doi = {10.1177/0894439305282430},
URL = {https://doi-org.crai.referencistas.com/10.1177/0894439305282430},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0894439305282430},
abstract = {Approaches to modeling social phenomena vary on a continuum from simple models, in which causality is clear and parameters few, to realistic, high-fidelity models designed to capture the most detailed system behavior possible in a specific setting. Anthropologists have produced both simple and high-fidelity models. The focus of this article is on high-fidelity modeling in anthropology and the special challenge its complexity presents for model comparison. Useful model comparison requires docking, or rendering models comparable, and the author presents a framework for docking based on the work of Axelrod, and Cioffi-Revilla and Gotts. Docking not only renders models more comparable, allowing for more traditional theory testing, but it also sharpens the discussion about the ontology of anthropological phenomena and how they are best represented as theories and models.}
}

@article{doi:10.1177/0954410016673394,
author = {Yimin Ma and Ming Chen and Qiang Wang and Fang Wang},
title = {Main helicopter rotor trimming using computational fluid dynamics method in forward flight},
journal = {Proceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering},
volume = {232},
number = {1},
pages = {169–179},
year = {2018e},
doi = {10.1177/0954410016673394},
URL = {https://doi-org.crai.referencistas.com/10.1177/0954410016673394},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0954410016673394},
abstract = {In this paper, a computational fluid dynamics trimming method is proposed and compared with wind tunnel experiment and the blade element method. The NASA’s generic ROBIN helicopter model is adopted for transient simulations to obtain the final main rotor trimming conditions. Totally three steps were applied to the computational fluid dynamics method. The first step is associated with no cyclic pitch motion, the second is regarding pure longitudinal cyclic pitch motion and the last is concerning with pure lateral cyclic pitch motion. At the same time, a simple linear equation system between the roll and pitching moment was established to get the final longitudinal and lateral cyclic pitch angles for the main rotor through the above three steps. An overset grid approach was used where the volume around each blade was modeled in an individual overset grid region. The rotor rotation was resolved with three degrees per time-step. Turbulence was modeled with the well-known SST K-omega model with second-order convection. The helicopter was in straight forward flight with an advance ratio of . Three sources of stick angles, which are also called rotor trimming angles, were shown and compared with each other. And the corresponding results were also plotted with a type of history plot in the computational fluid dynamics condition. In the simulations, the results became quasi periodic after about 1.5 rotations and four rotor rotations were simulated for each case. The pitch moment coefficient and roll moment coefficient were all trimmed to about zero by the computational fluid dynamics trimming method while moments were not removed thoroughly in the other two source conditions.}
}

@article{doi:10.1177/0047239517748936,
author = {Rob Nyland},
title = {A Review of Tools and Techniques for Data-Enabled Formative Assessment},
journal = {Journal of Educational Technology Systems},
volume = {46},
number = {4},
pages = {505–526},
year = {2018f},
doi = {10.1177/0047239517748936},
URL = {https://doi-org.crai.referencistas.com/10.1177/0047239517748936},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0047239517748936},
abstract = {The purpose of this literature review is to understand the current state of research on tools that collect data for the purpose of formative assessment. We were interested in identifying the types of data collected by these tools, how these data were processed, and how the processed data were presented to the instructor or student for the purpose of formative assessment. We identified two categories of data: machine-graded and activity stream data. The data were processed using three methods: unprocessed activity streams, descriptive data analysis, and data mining. Processed data were presented to students through reports and real-time feedback and to instructors through reports and visual dashboards.}
}

@article{doi:10.1243/09544070JAUTO1434,
author = {X-Y Shi and X-Q Qiao and J-M Ni and Y-Y Zheng and N-Y Ye},
title = {Study on the combustion and emission characteristics of a diesel engine with multi-injection modes based on experimental investigation and computational fluid dynamics modelling},
journal = {Proceedings of the Institution of Mechanical Engineers, Part D: Journal of Automobile Engineering},
volume = {224},
number = {9},
pages = {1161–1176},
year = {2010g},
doi = {10.1243/09544070JAUTO1434},
URL = {https://doi-org.crai.referencistas.com/10.1243/09544070JAUTO1434},
eprint = {https://doi-org.crai.referencistas.com/10.1243/09544070JAUTO1434},
abstract = {Abstract In this paper, experiments were carried out on a direct-injection diesel engine using a common-rail system, in order to study the effects of multi-injection modes on the combustion characteristics and pollutant emissions. A soot model was proposed for the post-injection mode, namely the Hiroyasu—Kodota averaged-reaction-rate soot model, which took into account both the chemical kinetics reaction and the turbulent mixing motion of the spray jet. Through integrating the revised soot model into a computational fluid dynamics (CFD) code, the combustion process and pollutants formation of the tested engine were simulated. The in-cylinder gas pressure and combustion heat release rate showed satisfactory agreement with measurements. The experimental data demonstrated that the pilot-injection mode was one of the most effective measures for reducing combustion noise. Meanwhile an optimum split-injection mode consisting of an appropriate pilot-injection fuel quantity combined with an optimal pilot-injection—main-injection interval could be achieved to decrease the nitrogen oxide (NOx) emission while not causing the particulate matter (PM) emission to deteriorate very much. Two innovative concepts of an active thermo-atmosphere and a passive inert atmosphere were presented from numerical simulation to discuss the effect of the pilot-injection mode on the combustion behaviour of the main injection. Regarding the post-injection mode, its prominent advantage was to decrease significantly the PM emission without an NOx emission penalty. Furthermore, by CFD modelling of the soot formation process, it can be observed that the turbulent mixing motion caused by the post-injection spray played a vital role in the soot oxidization process.}
}

@article{doi:10.1177/0957650913513253,
author = {Jörg Starzmann and Michael M Casey and Jürgen F Mayer and Frank Sieverding},
title = {Wetness loss prediction for a low pressure steam turbine using computational fluid dynamics},
journal = {Proceedings of the Institution of Mechanical Engineers, Part A: Journal of Power and Energy},
volume = {228},
number = {2},
pages = {216–231},
year = {2014h},
doi = {10.1177/0957650913513253},
URL = {https://doi-org.crai.referencistas.com/10.1177/0957650913513253},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0957650913513253},
abstract = {Two-phase computational fluid dynamics modelling is used to investigate the magnitude of different contributions to the wet steam losses in a three-stage model low pressure steam turbine. The thermodynamic losses (due to irreversible heat transfer across a finite temperature difference) and the kinematic relaxation losses (due to the frictional drag of the drops) are evaluated directly from the computational fluid dynamics simulation using a concept based on entropy production rates. The braking losses (due to the impact of large drops on the rotor) are investigated by a separate numerical prediction. The simulations show that in the present case, the dominant effect is the thermodynamic loss that accounts for over 90% of the wetness losses and that both the thermodynamic and the kinematic relaxation losses depend on the droplet diameter. The numerical results are brought into context with the well-known Baumann correlation, and a comparison with available measurement data in the literature is given. The ability of the numerical approach to predict the main wetness losses is confirmed, which permits the use of computational fluid dynamics for further studies on wetness loss correlations.}
}

@article{doi:10.1177/0894439306293820,
author = {Levent Yilmaz},
title = {Toward Next-Generation, Simulation-Based Computational Tools for Conflict and Peace Studies},
journal = {Social Science Computer Review},
volume = {25},
number = {1},
pages = {48–60},
year = {2007i},
doi = {10.1177/0894439306293820},
URL = {https://doi-org.crai.referencistas.com/10.1177/0894439306293820},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0894439306293820},
abstract = {Human, social, and international conflicts are inescapable facts of life. This article elaborates on how advances in simulation theory and methodology can improve exploring and studying the dynamics of conflicts. The premise of the proposed strategy is based on the observation that agent-based social simulation, which enables high-level and powerful problem-solving capabilities, needs to be significantly enhanced to model complex, multilevel, and multistaged conflicts. To this end, the issues, challenges, and rationale underlying a novel simulation methodology, called multisimulation, are explained. The conceptual foundations needed for the realization of multisimulation are presented to contribute to the development of advanced simulation-based computational laboratories for conflict studies. Finally, by using the Bloomfield-Leiss dynamic phase model of conflict, the author argues for the utility of multisimulation.}
}

@article{doi:10.1177/001316447803800318,
author = {Thomas J. Zenisek},
title = {Three-Mode Factor Analysis Via a Modification of Tucker’s Computational Method—III},
journal = {Educational and Psychological Measurement},
volume = {38},
number = {3},
pages = {787–792},
year = {1978j},
doi = {10.1177/001316447803800318},
URL = {https://doi-org.crai.referencistas.com/10.1177/001316447803800318},
eprint = {https://doi-org.crai.referencistas.com/10.1177/001316447803800318},
abstract = {A FORTRAN G/H computer program was derived for an IBM series 360/370 computer system (or compatible systems such as Amdol or Honeywell) that provides at least 1536-K of core storage. This large amount of core storage is usually provided via a VS-1 or VS-2 virtual memory system. This program provides a factor analytic solution for large 3-dimensional data matrices. The computational procedures employed are based upon those presented in Method III of Tucker (1966).}
}

