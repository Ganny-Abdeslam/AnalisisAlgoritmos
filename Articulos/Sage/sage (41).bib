@article{doi:10.1177/104538902761696814,
author = {H. T. Banks and D. G. Cole and K. M. Furati and K. Ito and G. A. Pinter},
title = {A Computational Model for Sound Field Absorption by Acoustic Arrays},
journal = {Journal of Intelligent Material Systems and Structures},
volume = {13},
number = {4},
pages = {231–240},
year = {2002a},
doi = {10.1177/104538902761696814},
URL = {https://doi-org.crai.referencistas.com/10.1177/104538902761696814},
eprint = {https://doi-org.crai.referencistas.com/10.1177/104538902761696814},
abstract = {In this paper we discuss the sound absorption property of arrays of micro-acoustic actuators at a control surface. We use the wave equation over the half plane for the velocity potential with a boundary dissipation by a proportional pressure feedback law along the half plane boundary. The feedback gain over the array is described by a distributed shape function. We develop a computational method based on the Fourier transform and employ it for analyzing and evaluating the decay rate of acoustic energy. Specifically, we carry out computations for a diffusive random initial field and report on our resulting numerical findings.}
}

@article{doi:10.1177/0894439320951766,
author = {Thomas Elliott and Misty Ring-Ramirez and Jennifer Earl},
title = {Spillover as Movement Agenda Setting: Using Computational and Network Techniques for Improved Rare Event Identification},
journal = {Social Science Computer Review},
volume = {39},
number = {5},
pages = {981–1002},
year = {2021b},
doi = {10.1177/0894439320951766},
URL = {https://doi-org.crai.referencistas.com/10.1177/0894439320951766},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0894439320951766},
abstract = {The increasing availability of data, along with sophisticated computational methods for analyzing them, presents researchers with new opportunities and challenges. In this article, we address both by describing computational and network methods that can be used to identify cases of rare phenomena. We evaluate each method’s relative utility in the identification of a specific rare phenomenon of interest to social movement researchers: the spillover of social movement claims from one movement to another. We identify and test five different approaches to detecting cases of spillover in the largest data set of protest events currently available, finding that an ensemble approach that combines clique and correspondence analysis and an ensemble approach combining all methods perform considerably better than others. Our approach is preferable to other ways of analyzing such cases; compared to qualitative approaches, our computational process identifies many more cases of spillover—some of which are surprising and would likely not be otherwise investigated. At the same time, compared to crude quantitative measures, our approach substantially reduces the “noise,” or identification of false-positive cases, of movement spillover. We argue that this technique, which can be adapted to other research topics, is a good illustration of how the thoughtful implementation of computational methods can allow for the efficient identification of rare events and also bridge deductive and inductive approaches to scientific inquiry.}
}

@article{doi:10.1177/20539517211062885,
author = {Federica Lucivero and Nina Hallowell},
title = {Digital/computational phenotyping: What are the differences in the science and the ethics?},
journal = {Big Data & Society},
volume = {8},
number = {2},
pages = {20539517211062884},
year = {2021c},
doi = {10.1177/20539517211062885},
URL = {https://doi-org.crai.referencistas.com/10.1177/20539517211062885},
eprint = {https://doi-org.crai.referencistas.com/10.1177/20539517211062885},
abstract = {The concept of ‘digital phenotyping’ was originally developed by researchers in the mental health field, but it has travelled to other disciplines and areas. This commentary draws upon our experiences of working in two scientific projects that are based at the University of Oxford’s Big Data Institute – The RADAR-AD project and The Minerva Initiative – which are developing algorithmic phenotyping technologies. We describe and analyse the concepts of digital biomarkers and computational phenotyping that underlie these projects, explain how they are linked to other research in digital phenotyping and compare and contrast some of their epistemological and ethical implications. In particular, we argue that the phenotyping paradigm in both projects is grounded on an assumption of ‘objectivity’ that is articulated in different ways depending on the role that is given to the computational/digital tools. Using the concept of ‘affordance’, we show how specific functionalities relate to potential uses and social implications of these technologies and argue that it is important to distinguish among them as the concept of digital phenotyping is increasingly being used with a variety of meanings.}
}

@article{doi:10.1177/0735633119887508,
author = {Yizhou Qian and James Lehman},
title = {An Investigation of High School Students’ Errors in Introductory Programming: A Data-Driven Approach},
journal = {Journal of Educational Computing Research},
volume = {58},
number = {5},
pages = {919–945},
year = {2020d},
doi = {10.1177/0735633119887508},
URL = {https://doi-org.crai.referencistas.com/10.1177/0735633119887508},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0735633119887508},
abstract = {This study implemented a data-driven approach to identify Chinese high school students’ common errors in a Java-based introductory programming course using the data in an automated assessment tool called the Mulberry. Students’ error-related behaviors were also analyzed, and their relationships to success in introductory programming were investigated. This study identified 15 common compilation errors and 6 common test errors. The results showed that these common errors accounted for a large proportion of all errors, so identifying the common errors is important to help students succeed in introductory programming courses. Based on these common errors, five underlying student difficulties were identified and are discussed. In addition, after analyzing existing measures of students’ error-related behaviors, we developed a measure called improvement rate to quantify students’ success in fixing errors. The results of our study suggest that students’ competence of improving code is important to their success in introductory programming. We recommend researchers design and develop automated assessment tools that provide feedback messages for common student errors and instructors who explicitly teach knowledge and skills of improving code in class.}
}

@article{doi:10.4137/BBI.S13403,
author = {Angélica Sabogal-Arango and George E. Barreto and David Ramírez-Sánchez and Juan González-Mendoza and Viviana Barreto and Ludis Morales and Janneth González},
title = {Computational Insights of the Interaction among Sea Anemones Neurotoxins and Kv1.3 Channel},
journal = {Bioinformatics and Biology Insights},
volume = {8},
number = { },
pages = {BBI.S13403},
year = {2014e},
doi = {10.4137/BBI.S13403},
note = {PMID:24812496},
URL = {https://doi-org.crai.referencistas.com/10.4137/BBI.S13403},
eprint = {https://doi-org.crai.referencistas.com/10.4137/BBI.S13403},
abstract = {Sea anemone neurotoxins are peptides that interact with Na+ and K+ channels, resulting in specific alterations on their functions. Some of these neurotoxins (1ROO, 1BGK, 2K9E, 1BEI) are important for the treatment of about 80 autoimmune disorders because of their specificity for Kv1.3 channel. The aim of this study was to identify the common residues among these neurotoxins by computational methods, and establish whether there is a pattern useful for the future generation of a treatment for autoimmune diseases. Our results showed eight new key common residues between the studied neurotoxins interacting with a histidine ring and the selectivity filter of the receptor, thus showing a possible pattern of interaction. This knowledge may serve as an input for the design of more promising drugs for autoimmune treatments.}
}

@article{doi:10.1177/089443930101900105,
author = {Desmond Saunders-Newton and Harold Scott},
title = {“But the Computer Said!”: Credible Uses of Computational Modeling in Public Sector Decision Making},
journal = {Social Science Computer Review},
volume = {19},
number = {1},
pages = {47–65},
year = {2001f},
doi = {10.1177/089443930101900105},
URL = {https://doi-org.crai.referencistas.com/10.1177/089443930101900105},
eprint = {https://doi-org.crai.referencistas.com/10.1177/089443930101900105},
abstract = {There has been a continued expansion of the uses of computer-based tools and techniques in public sector endeavors: from traditional notions of data collection and management (bean counting) to the processing of data into information that supports managerial activities. Advances in technology based on emerging work in decision theory, information science, and cognitive science will allow for use of these computational models in more expansive “advisory” roles to decision makers of all types. To what degree can public sector decision makers use computational models to support or advise decision making? As these new technologies become a routine part of the policy process, will a belief in computer omnipotence tempt public sector decision makers to abdicate personal responsibility for poor choices? The authors explore the choice-related implications associated with the increased use of computer-based models, define possible computer-based decision support models (CBDSMs), and present a typology of credible uses of CBDSMs.}
}

@article{doi:10.1177/154193120004402124,
author = {Pamela S. Tsang},
title = {Mental Workload Beyond Computational Complexity},
journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
volume = {44},
number = {21},
pages = {3-468-3–471},
year = {2000g},
doi = {10.1177/154193120004402124},
URL = {https://doi-org.crai.referencistas.com/10.1177/154193120004402124},
eprint = {https://doi-org.crai.referencistas.com/10.1177/154193120004402124},
abstract = {The information processing approach traditionally has been the theoretical foundation of mental workload. Computational neurocognitive models are emerging approaches to understanding how the brain performs cognitive functions. Computational complexity refers to the many possibilities and ambiguities intrinsic in the environmental stimuli. These models agree that the brain has limited computational power. Utility and implications of the computational approaches to the understanding of mental workload, especially that of higher-level activities such as strategic control of dynamic multiple-task performance and situation awareness will be explored.}
}

@article{doi:10.1177/2398212818810591,
author = {Anthony G. Vaccaro and Stephen M. Fleming},
title = {Thinking about thinking: A coordinate-based meta-analysis of neuroimaging studies of metacognitive judgements},
journal = {Brain and Neuroscience Advances},
volume = {2},
number = { },
pages = {2398212818810591},
year = {2018h},
doi = {10.1177/2398212818810591},
note = {PMID:30542659},
URL = {https://doi-org.crai.referencistas.com/10.1177/2398212818810591},
eprint = {https://doi-org.crai.referencistas.com/10.1177/2398212818810591},
abstract = {Metacognition supports reflection upon and control of other cognitive processes. Despite metacognition occupying a central role in human psychology, its neural substrates remain underdetermined, partly due to study-specific differences in task domain and type of metacognitive judgement under study. It is also unclear how metacognition relates to other apparently similar abilities that depend on recursive thought such as theory of mind or mentalising. Now that neuroimaging studies of metacognition are more prevalent, we have an opportunity to characterise consistencies in neural substrates identified across different analysis types and domains. Here we used quantitative activation likelihood estimation methods to synthesise findings from 47 neuroimaging studies on metacognition, divided into categories based on the target of metacognitive evaluation (memory and decision-making), analysis type (judgement-related activation, confidence-related activation, and predictors of metacognitive sensitivity), and, for metamemory judgements, temporal focus (prospective and retrospective). A domain-general network, including medial and lateral prefrontal cortex, precuneus, and insula was associated with the level of confidence in self-performance in both decision-making and memory tasks. We found preferential engagement of right anterior dorsolateral prefrontal cortex in metadecision experiments and bilateral parahippocampal cortex in metamemory experiments. Results on metacognitive sensitivity were inconclusive, likely due to fewer studies reporting this contrast. Finally, by comparing our results to meta-analyses of mentalising, we obtain evidence for common engagement of the ventromedial and anterior dorsomedial prefrontal cortex in both metacognition and mentalising, suggesting that these regions may support second-order representations for thinking about the thoughts of oneself and others.}
}

@article{doi:10.1177/1687814017734109,
author = {Miao Wang and Xinhai Xu and Xiaoguang Ren and Chao Li and Juan Chen and Xuejun Yang},
title = {Mesh partitioning using matrix value approximations for parallel computational fluid dynamics simulations},
journal = {Advances in Mechanical Engineering},
volume = {9},
number = {11},
pages = {1687814017734109},
year = {2017i},
doi = {10.1177/1687814017734109},
URL = {https://doi-org.crai.referencistas.com/10.1177/1687814017734109},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1687814017734109},
abstract = {Mesh partitioning is significant to the efficiency of parallel computational fluid dynamics simulations. The most time-consuming parts of parallel computational fluid dynamics simulations are iteratively solving linear systems derived from partial differential equation discretizations. This article aims at mesh partitioning for better iterative convergence feature of this procedure. For typical computational fluid dynamics simulations in which partial differential equations are discretized and solved after the mesh is partitioned, numerical information of the linear systems is not available yet during mesh partitioning. We propose to construct approximations for matrix elements and theoretically find out that for finite-volume-based problems, the face area can approximate the corresponding matrix element well. A mesh partitioning scheme using the matrix value approximations for better iterative convergence behavior is implemented and numerically testified. The results show that our method can capture the most important factor influencing the matrix values and achieve partitions with good performance throughout the simulations with non-uniform meshes. The novel partitioning strategy is general and easy to implement in various partitioning packages.}
}

@article{doi:10.1177/1056789508090748,
author = {A.H. Zhao and C.L. Chow},
title = {Computational Algorithms for a Damage-coupled Cyclic Viscoplasticity Material Model},
journal = {International Journal of Damage Mechanics},
volume = {18},
number = {6},
pages = {507–532},
year = {2009j},
doi = {10.1177/1056789508090748},
URL = {https://doi-org.crai.referencistas.com/10.1177/1056789508090748},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1056789508090748},
abstract = {The primary objective of this investigation is to develop efficient and robust computational schemes for a damage-coupled cyclic thermoviscoplasticity model for solder materials. Three constitutive integration algorithms, Euler, modified Euler, and semi-implicit algorithm for the model are examined. The three algorithms for the model are coded in the commercial finite element (FE) code ABAQUS (version 6.21) via its user-defined material subroutine UMAT. Two single-step algorithms of the substep scheme are applied for the modified Euler algorithm to control the error in the integration of constitutive laws. A semi-empirical formulation is established for an adaptive time stepping algorithm that is based on the Euler algorithm. The simulations of single-element, miniature specimen and notched specimen simulations have been conducted and compared with the test results under monotonic tensile, creep, and fatigue tests of 63Sn-37Pb solder. It is observed that the explicit algorithm consistently requires much less CPU time than others. The modified Euler algorithm has shown, on the other hand, to be not only efficient but also accurate. The semi-implicit algorithm yields an accurate solution. It is worth noting that the method is also effective by applying an appropriate integration scheme.}
}

