@article{doi:10.1243/09576509JPE368,
author = {M A R Sadiq Al-Baghdadi and H A K Shahad Al-Janabi},
title = {Prediction of hygro—thermal stress distribution in proton exchange membranes using a three-dimensional multi-phase computational fluid dynamics model},
journal = {Proceedings of the Institution of Mechanical Engineers, Part A: Journal of Power and Energy},
volume = {221},
number = {7},
pages = {941–953},
year = {2007a},
doi = {10.1243/09576509JPE368},
URL = {https://doi-org.crai.referencistas.com/10.1243/09576509JPE368},
eprint = {https://doi-org.crai.referencistas.com/10.1243/09576509JPE368},
abstract = {Abstract A three-dimensional, multi-phase, non-isothermal computational fluid dynamics model of a proton exchange membrane fuel cell has been developed to simulate the hygro and thermal stresses in polymer membrane, which developed during the cell operation. The behaviour of the membrane during the operation of a unit cell has been studied and investigated. The model accounts for both gas and liquid phase in the same computational domain, and thus allows for the implementation of phase change inside the gas diffusion layers. The model includes the transport of gaseous species, liquid water, protons, energy, and water dissolved in the ion-conducting polymer. The new feature of the present model is to incorporate the effect of hygro and thermal stresses into actual three-dimensional, multi-phase, non-isothermal fuel cell model. In addition to hygro—thermal stresses, the model features an algorithm that allows for a more realistic representation of the local activation overpotentials, which leads to improved prediction of the local current density distribution in high accuracy, and therefore, high accuracy prediction of temperature distribution in the cell and then thermal stresses. This model also takes into account convection and diffusion of different species in the channels as well as in the porous gas diffusion layer, heat transfer in the solids as well as in the gases, and electrochemical reactions.}
}

@article{doi:10.2466/pms.1978.46.1.323,
author = {Jon M. Engelhardt},
title = {Cognitive Style and Children’s Computational Errors},
journal = {Perceptual and Motor Skills},
volume = {46},
number = {1},
pages = {323–330},
year = {1978b},
doi = {10.2466/pms.1978.46.1.323},
URL = {https://doi-org.crai.referencistas.com/10.2466/pms.1978.46.1.323},
eprint = {https://doi-org.crai.referencistas.com/10.2466/pms.1978.46.1.323},
abstract = {The present study investigated whether for children with analytic-nonanalytic/impulsive-reflective cognitive styles the tendency to exhibit different types of computational errors in arithmetic are related. 198 students from Grades 3 and 6 were drawn from two school districts. Tests of cognitive style and a computation test were administered. Subjects’ types of errors and cognitive styles only tentatively confirmed a relationship between the dimensions of cognitive style and types of errors.}
}

@article{doi:10.1177/0954406218769919,
author = {Bruce Garvey and Liuqing Chen and Feng Shi and Ji Han and Peter RN Childs},
title = {New directions in computational, combinational and structural creativity},
journal = {Proceedings of the Institution of Mechanical Engineers, Part C: Journal of Mechanical Engineering Science},
volume = {233},
number = {2},
pages = {425–431},
year = {2019c},
doi = {10.1177/0954406218769919},
URL = {https://doi-org.crai.referencistas.com/10.1177/0954406218769919},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0954406218769919},
abstract = {This paper examines how new and creative relationships in datasets, not easily revealed by conventional information retrieval methods and technologies, can be identified using a mix of established and new methods. The authors present how the integration of computerised morphological analysis with new computational models, incorporating web crawler, data processing networking and data mining algorithms, can help facilitate the identification of new ideas. Boden’s concept of ‘Combinational Creativity’ indicates a structured process, which generates unfamiliar combinations of familiar concepts and constructs allowing creative styles of thought. This structured approach has been constrained by the resultant combinatorial explosion and the dearth of easily accessible computer software and supporting methodologies, to help identify viable new solutions. Feature-enhanced computerised morphological analysis provides a new structural support tool for creativity and innovation. Morphological analysis systematically structures and examines all the possible relationships in a multidimensional, highly complex, usually non-quantifiable problem space. Computerisation of the process now permits large number of configurations (millions) in the problem space to be majorly reduced (typically > 95%), identifying only internally consistent solutions. These solutions are likely to embrace configurations containing something, which has not previously been considered, thus increasing the probability of some form of technological or design breakthrough and hence truly creative.}
}

@article{doi:10.3233/CI-2009-0017,
author = {Alberto Gobbi and Matthew Lardy and Sun Hee Kim and Frank Ruebsam and Martin Tran and Stephen E. Webber and Alan X. Xiang},
title = {Illuminator: Increasing Synergies Between Medicinal And     Computational Chemists},
journal = {In Silico Biology},
volume = {11},
number = {1–2},
pages = {83–93},
year = {2012d},
doi = {10.3233/CI-2009-0017},
URL = {https://doi-org.crai.referencistas.com/10.3233/CI-2009-0017},
eprint = {https://doi-org.crai.referencistas.com/10.3233/CI-2009-0017},
abstract = {We present Illuminator, a user-friendly web front end to computational models such as docking and 3D shape similarity calculations. Illuminator was specifically created to allow non-experts to design and submit molecules to computational chemistry programs. As such it provides a simple user interface allowing users to submit jobs starting from a 2D structure. The models provided are pre-optimized by computational chemists for each specific target. We provide an example of how Illuminator was used to prioritize the design of molecular substituents in the Anadys HCV Polymerase (NS5B) project. With 7500 submitted jobs in 1.5 years, Illuminator has allowed project teams at Anadys to accelerate the optimization of novel leads. It has also improved communication between project members and increased demand for computational drug discovery tools.}
}

@article{doi:10.1177/1744259118771314,
author = {Susana Hormigos-Jimenez and Miguel Ángel Padilla-Marcos and Alberto Meiss and Roberto Alonso Gonzalez-Lezcano and Jesús Feijó-Muñoz},
title = {Assessment of the ventilation efficiency in the breathing zone during sleep through computational fluid dynamics techniques},
journal = {Journal of Building Physics},
volume = {42},
number = {4},
pages = {458–483},
year = {2019e},
doi = {10.1177/1744259118771314},
URL = {https://doi-org.crai.referencistas.com/10.1177/1744259118771314},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1744259118771314},
abstract = {In developed countries, presence at home varies between 60% and 90% of the day, sleeping supposes 30%. Therefore, it is essential to ensure good indoor air quality that enhances health and benefits rest and recovery. In this context, it is necessary to achieve a balance between energy efficiency and air distribution parameters; thus, the influence exerted by the furniture of a bedroom on the air exchange efficiency, in the breathing zone during sleep, is assessed in this study. Computational fluid dynamics techniques, experimentally validated by the tracer gas (SF6) concentration decay method, are used to analyze 52 case studies corresponding to the same space, but varying both the number and the arrangement of the furniture inside. It is concluded that, in order to achieve a significant improvement in the air exchange efficiency, the number of elements included in the bedroom is not relevant, but the position of them. The highest increase in the ventilation efficiency in breathing zone is observed when the furniture is located avoiding the airflow obstruction in the area near the inlet and creating an unfilled volume of air in the area close to the outlet.}
}

@article{doi:10.1177/0033294118806473,
author = {Paul A. Klaczynski and Wejdan Felmban},
title = {Effects of Thinking Dispositions, General Ability, Numeracy, and Instructional Set on Judgments and Decision-Making},
journal = {Psychological Reports},
volume = {123},
number = {2},
pages = {341–370},
year = {2020f},
doi = {10.1177/0033294118806473},
note = {PMID:30550725},
URL = {https://doi-org.crai.referencistas.com/10.1177/0033294118806473},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0033294118806473},
abstract = {To explore hypotheses based on Stanovich’s proposal that analytic processing comprises a reflective-level, an algorithmic level, and specific mindware, 342 participants completed measures of thinking dispositions, general ability (GA), numeracy, and probabilistic and nonprobabilistic reasoning. In a control condition, numeracy predicted probabilistic reasoning at high levels of both thinking dispositions and GA, and GA predicted nonprobabilistic reasoning at high levels of thinking dispositions. In a logic instruction condition, numeracy predicted probabilistic reasoning when GA was high, and GA affected nonprobabilistic reasoning directly. Thinking dispositions moderated neither relationship. Instead, instructions facilitated reasoning for low thinking disposition/high-ability participants, suggesting that logic instructions cued low thinking disposition individuals to engage in higher order reflective processing. The evidence is consistent with the proposals that reflective processes are essential to the allocation of algorithmic resources, and algorithmic resources are necessary for effective mindware implementation.}
}

@article{doi:10.1177/1934578X221096966,
author = {Ying Liu and Han Yan and Hui-bin Jia and Li Pan and Jia-zheng Liu and Ya-wen Zhang and Jing Wang and Dao-gang Qin and Lei Ma and Ting Wang},
title = {Jiedu Huoxue Decoction for Cytokine Storm and Thrombosis in Severe COVID-19: A Combined Bioinformatics and Computational Chemistry Approach},
journal = {Natural Product Communications},
volume = {17},
number = {4},
pages = {1934578X221096966},
year = {2022g},
doi = {10.1177/1934578X221096966},
URL = {https://doi-org.crai.referencistas.com/10.1177/1934578X221096966},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1934578X221096966},
abstract = {Jiedu Huoxue Decoction (JHD), a recommended traditional prescription for patients with severe COVID-19, has appeared in the treatment protocols in China. Based on bioinformatics and computational chemistry methods, including molecular docking, molecular dynamics (MD) simulation, and Molecular Mechanics Generalized Born Surface Area (MM/GBSA) calculation, we aimed to reveal the mechanism of JHD in treating severe COVID-19. The compounds in JHD were obtained and screened on TCMSP, SwissADME, and ADMETLab platforms. The compound targets were obtained from TCMSP and STITCH, while COVID-19 targets were obtained from Genecards and NCBI. The protein-protein interaction network was constructed by using STRING. Gene Ontology (GO) and KEGG enrichment were performed with ClueGO and R language. AutoDock vina was employed for molecular docking. 100 ns MD simulation of the optimal docking complex was carried out with AmberTools 20. A total of 84 compounds and 29 potential targets of JHD for COVID-19 were collected. The key phytochemicals included quercetin, luteolin, β-sitosterol, puerarin, stigmasterol, kaempferol, and wogonin, which could regulate the immune system. The hub genes included IL6, IL10, VEGFA, IL1B, CCL2, HMOX1, DPP4, and ACE2. ACE2 and DPP4 were related to SARS-CoV-2 entering cells. GO and KEGG analysis showed that JHD could intervene in cytokine storm and endothelial proliferation and migration related to thrombosis. The molecular docking, 100 ns MD simulation, and MM/GBSA calculation confirmed that targets enriched in the COVID-19 pathway had high affinities with related compounds, and the conformations of the puerarin-ACE2, quercetin-EGFR, luteolin-EGFR, and quercetin-IL1B complexes were stable. In a word, JHD could treat COVID-19 by intervening in cytokine storm, thrombosis, and the entry of SARS-CoV-2, while regulating the immune system. These mechanisms were consistent with JHD’s therapeutic concept of “detoxification” and “promoting blood circulation and removing blood stasis” in treating COVID-19. The research provides a theoretical basis for the development and application of JHD.}
}

@article{doi:10.1080/17470218.2015.1134602,
author = {Pavel Logačev and Shravan Vasishth},
title = {Understanding underspecification: A comparison of two computational implementations},
journal = {Quarterly Journal of Experimental Psychology},
volume = {69},
number = {5},
pages = {996–1012},
year = {2016h},
doi = {10.1080/17470218.2015.1134602},
note = {PMID:26960441},
URL = {https://doi-org.crai.referencistas.com/10.1080/17470218.2015.1134602},
eprint = {https://doi-org.crai.referencistas.com/10.1080/17470218.2015.1134602},
abstract = {Swets et al. (2008. Underspecification of syntactic ambiguities: Evidence from self-paced reading. Memory and Cognition, 36(1), 201–216) presented evidence that the so-called ambiguity advantage [Traxler et al. (1998). Adjunct attachment is not a form of lexical ambiguity resolution. Journal of Memory and Language, 39(4), 558–592], which has been explained in terms of the Unrestricted Race Model, can equally well be explained by assuming underspecification in ambiguous conditions driven by task-demands. Specifically, if comprehension questions require that ambiguities be resolved, the parser tends to make an attachment: when questions are about superficial aspects of the target sentence, readers tend to pursue an underspecification strategy. It is reasonable to assume that individual differences in strategy will play a significant role in the application of such strategies, so that studying average behaviour may not be informative. In order to study the predictions of the good-enough processing theory, we implemented two versions of underspecification: the partial specification model (PSM), which is an implementation of the Swets et al. proposal, and a more parsimonious version, the non-specification model (NSM). We evaluate the relative fit of these two kinds of underspecification to Swets et al.’s data; as a baseline, we also fitted three models that assume no underspecification. We find that a model without underspecification provides a somewhat better fit than both underspecification models, while the NSM model provides a better fit than the PSM. We interpret the results as lack of unambiguous evidence in favour of underspecification; however, given that there is considerable existing evidence for good-enough processing in the literature, it is reasonable to assume that some underspecification might occur. Under this assumption, the results can be interpreted as tentative evidence for NSM over PSM. More generally, our work provides a method for choosing between models of real-time processes in sentence comprehension that make qualitative predictions about the relationship between several dependent variables. We believe that sentence processing research will greatly benefit from a wider use of such methods.}
}

@article{doi:10.1177/026765839200800104,
author = {Manfred Pienemann},
title = {COALA-A computational system for interlanguage analysis},
journal = {Interlanguage studies bulletin (Utrecht)},
volume = {8},
number = {1},
pages = {59–92},
year = {1992i},
doi = {10.1177/026765839200800104},
URL = {https://doi-org.crai.referencistas.com/10.1177/026765839200800104},
eprint = {https://doi-org.crai.referencistas.com/10.1177/026765839200800104},
abstract = {This article describes a computational system for the linguistic analysis of language acquisition data (COALA). The system is a combined AI and database tool which allows the user to form highly complex queries about morphosyntactic and semantic structures contained in large sets of data. COALA identifies those sentences that meet the linguistic criteria defined by the user. It allows the user to freely define such linguistic contexts and to step through the sentences identified by the system. COALA then rapidly displays those sentences in their original discourse context. Additionally, COALA can perform statistical analyses in response to structural linguistic queries. This article contains (1) a discussion of the computational approach taken in the design of COALA, (2) a description of the functionality of the system, and (3) a reflection on the validity of the analytical categories contained therein.}
}

@article{doi:10.1177/1478077120976493,
author = {Malgorzata A Zboinska and Delia Dumitrescu},
title = {On the aesthetic significance of imprecision in computational design: Exploring expressive features of imprecision in four digital fabrication approaches},
journal = {International Journal of Architectural Computing},
volume = {19},
number = {3},
pages = {250–272},
year = {2021j},
doi = {10.1177/1478077120976493},
URL = {https://doi-org.crai.referencistas.com/10.1177/1478077120976493},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1478077120976493},
abstract = {Precision of materialized designs is the conventional goal of digital fabrication in architecture. Recently, however, an alternative concept has emerged which refashions the imprecisions of digital processes into creative opportunities. While the computational design community has embraced this idea, its novelty results in a yet incomplete understanding. Prompted by the challenge of the still missing knowledge, this study explored imprecision in four digital fabrication approaches to establish how it influences the aesthetic attributes of materialized designs. Imprecision occurrences for four different digitally aided materialization processes were characterized. The aesthetic features emerging from these imprecisions were also identified and the possibilities of tampering with them for design exploration purposes were discussed. By considering the aesthetic potentials of deliberate imprecision, the study has sought to challenge the canon of high fidelity in contemporary computational design and to argue for imprecision in computation that shapes a new generation of designs featuring the new aesthetic of computational imperfection.}
}

